{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "8f542f44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[autoreload of ChEmbed.modules.simple_rnn failed: Traceback (most recent call last):\n",
      "  File \"/home/patrick/miniconda3/envs/d2l/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 276, in check\n",
      "    superreload(m, reload, self.old_objects)\n",
      "  File \"/home/patrick/miniconda3/envs/d2l/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 500, in superreload\n",
      "    update_generic(old_obj, new_obj)\n",
      "  File \"/home/patrick/miniconda3/envs/d2l/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 397, in update_generic\n",
      "    update(a, b)\n",
      "  File \"/home/patrick/miniconda3/envs/d2l/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 365, in update_class\n",
      "    update_instances(old, new)\n",
      "  File \"/home/patrick/miniconda3/envs/d2l/lib/python3.9/site-packages/IPython/extensions/autoreload.py\", line 323, in update_instances\n",
      "    object.__setattr__(ref, \"__class__\", new)\n",
      "TypeError: __class__ assignment: 'simpleRNN' object layout differs from 'simpleRNN'\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a799a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../../\")\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "import torch\n",
    "\n",
    "from ChEmbed.data import chembldb, datasets, chembed_tokenize, shakespeare_dataset\n",
    "from ChEmbed.training import trainer\n",
    "from ChEmbed.modules import simple_rnn\n",
    "import attr\n",
    "\n",
    "from ChEmbed import plots, utilities\n",
    "\n",
    "from transformers.tokenization_utils_fast import PreTrainedTokenizerFast\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "import torch\n",
    "import attrs\n",
    "from torch import nn, optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e763b82",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "826c812f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_indices_to_string(encoded_indices: list, idx_to_char_mapping: dict[int, str]):\n",
    "    decoded = ''.join([idx_to_char_mapping[int(inx)] for inx in encoded_indices])\n",
    "    return decoded\n",
    "\n",
    "def encode_string_to_indices(smiles_string: str, char_to_idx_mapping: dict[str, int]):\n",
    "    encoded = [char_to_idx_mapping[c] for c in smiles_string]\n",
    "    return encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9912d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "chembl_raw = chembldb.ChemblDBChemreps()\n",
    "chembl_smiles = chembl_raw._load_or_download()[\"canonical_smiles\"].to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "0542c447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Cc1cc(-c2csc(N=C(N)N)n2)cn1C',\n",
       " 'CC[C@H](C)[C@H](NC(=O)[C@H](CC(C)C)NC(=O)[C@@H](NC(=O)[C@@H](N)CCSC)[C@@H](C)O)C(=O)NCC(=O)N[C@@H](C)C(=O)N[C@@H](C)C(=O)N[C@@H](Cc1c[nH]cn1)C(=O)N[C@@H](CC(N)=O)C(=O)NCC(=O)N[C@@H](C)C(=O)N[C@@H](C)C(=O)N[C@@H](CCC(N)=O)C(=O)N[C@@H](CC(C)C)C(=O)N[C@@H](CC(C)C)C(=O)N[C@@H](CCCN=C(N)N)C(=O)N[C@@H](CCC(N)=O)C(=O)N[C@@H](CC(C)C)C(=O)N[C@@H](CCCN=C(N)N)C(=O)NCC(=O)N[C@@H](CCC(N)=O)C(=O)N[C@@H](CC(C)C)C(=O)NCC(=O)N1CCC[C@H]1C(=O)N1CCC[C@H]1C(=O)NCC(=O)N[C@@H](CO)C(=O)N[C@@H](CCCN=C(N)N)C(N)=O',\n",
       " 'CCCC[C@@H]1NC(=O)[C@@H](NC(=O)[C@H](CC(C)C)NC(=O)[C@@H](NC(=O)[C@H](CCC(=O)O)NC(=O)[C@H](CCCN=C(N)N)NC(=O)[C@H](CC(C)C)NC(=O)[C@H](CC(C)C)NC(=O)[C@H](Cc2c[nH]cn2)NC(=O)[C@H](N)Cc2ccccc2)C(C)C)CCC(=O)NCCCC[C@@H](C(=O)N[C@@H](CCC(N)=O)C(=O)N[C@@H](CC(C)C)C(=O)N[C@@H](C)C(=O)N[C@@H](CCC(N)=O)C(=O)N[C@@H](CCC(N)=O)C(=O)N[C@@H](C)C(=O)N[C@@H](Cc2c[nH]cn2)C(=O)N[C@@H](CO)C(=O)N[C@@H](CC(N)=O)C(=O)N[C@@H](CCCN=C(N)N)C(=O)N[C@@H](CCCCN)C(=O)N[C@@H](CC(C)C)C(=O)N[C@@H](CCCC)C(=O)N[C@@H](CCC(=O)O)C(=O)N[C@H](C(=O)N[C@H](C(=O)C(N)=O)[C@@H](C)CC)[C@@H](C)CC)NC(=O)[C@H](C)NC(=O)[C@H](CCCN=C(N)N)NC(=O)[C@H](C)NC1=O',\n",
       " 'CC(C)C[C@@H]1NC(=O)CNC(=O)[C@H](c2ccc(O)cc2)NC(=O)[C@@H]([C@@H](C)O)NC(=O)[C@H](c2ccc(O[C@H]3O[C@H](CO)[C@@H](O)[C@H](O)[C@@H]3O[C@H]3O[C@H](CO)[C@@H](O)[C@H](O)[C@@H]3O)cc2)NC(=O)[C@@H](CCCN)NC(=O)[C@H](Cc2ccccc2)NC(=O)[C@H]([C@@H](C)O)NC(=O)[C@@H](c2ccc(O)cc2)NC(=O)[C@H](c2ccc(O)cc2)NC(=O)[C@@H](C(C)C)NC(=O)[C@@H](CCCN)NC(=O)[C@@H](c2ccc(O)cc2)NC(=O)[C@@H](CNC(=O)[C@H](CC(N)=O)NC(=O)Cc2cccc3ccccc23)[C@@H](C(N)=O)OC(=O)[C@H](c2ccc(O)c(Cl)c2)NC(=O)[C@@H](C)NC1=O',\n",
       " 'Brc1cccc(Nc2ncnc3ccncc23)c1NCCN1CCOCC1',\n",
       " 'COc1c(O)cc(O)c(C(=N)Cc2ccc(O)cc2)c1O',\n",
       " 'CCOC(=O)c1cc2cc(C(=O)O)ccc2[nH]1',\n",
       " 'CC(=O)O[C@@H]1[C@@H](OC(C)=O)/C(C)=C\\\\[C@@H]2OC(=O)[C@]3(C)O[C@]23[C@H](OC(C)=O)[C@H]2[C@](C)(O)[C@H](O)C=C[C@]2(C)[C@H]1OC(C)=O',\n",
       " 'C[C@H](NC(=O)OCc1ccccc1)C(=O)N[C@@H](C)C(=O)NN(CC(N)=O)C(=O)/C=C/C(=O)N(Cc1ccco1)Cc1ccco1',\n",
       " 'CO[C@H]1C[C@H](COC[C@H]2[C@@H](OC)C[C@H](O[C@H]3CC[C@@]4(C)C(=CC[C@]5(O)[C@@H]4C[C@@H](OC(=O)/C=C/c4ccccc4)[C@@]4(C)[C@]5(O)CC[C@@]4(O)C(C)=O)C3)O[C@@H]2C)O[C@@H](C)[C@H]1COC[C@H]1C[C@H](OC)[C@H](COC[C@H]2C[C@@H](OC)[C@@H](O[C@H]3O[C@@H](CO)[C@H](O)[C@@H](O)[C@@H]3O)[C@H](C)O2)[C@@H](C)O1']"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chembl_smiles[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a2d54ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "chembl_mini = datasets.CharacterLevelSMILES(\n",
    "    smiles_list = chembl_smiles[:100000],\n",
    "    length = 256,\n",
    "    batch_size = 128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "7656459f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5511270"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(chembl_mini.all_smiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "82ff81cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = simple_rnn.simpleRNN(\n",
    "    # Mandatory\n",
    "    num_hiddens = 512,\n",
    "    vocab_size = len(chembl_mini.characters),\n",
    "    # tuning\n",
    "    learning_rate = 0.001,\n",
    "    weight_decay = 1e-4,\n",
    "    num_layers = 3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "0113bcf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training batch 12/135... (Epoch 1/32)\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/32: Train Loss: 2.1607, Val Loss: 1.1749\n",
      "Epoch 2/32: Train Loss: 1.0800, Val Loss: 0.9705\n",
      "Epoch 3/32: Train Loss: 0.9493, Val Loss: 0.9045\n",
      "Epoch 4/32: Train Loss: 0.8911, Val Loss: 0.8662\n",
      "Epoch 5/32: Train Loss: 0.8496, Val Loss: 0.8433\n",
      "Epoch 6/32: Train Loss: 0.8206, Val Loss: 0.8312\n",
      "Epoch 7/32: Train Loss: 0.7990, Val Loss: 0.8091\n",
      "Epoch 8/32: Train Loss: 0.7805, Val Loss: 0.7991\n",
      "Epoch 9/32: Train Loss: 0.7646, Val Loss: 0.7922\n",
      "Epoch 10/32: Train Loss: 0.7527, Val Loss: 0.7991\n",
      "Epoch 11/32: Train Loss: 0.7420, Val Loss: 0.7845\n",
      "Epoch 12/32: Train Loss: 0.7309, Val Loss: 0.7801\n",
      "Epoch 13/32: Train Loss: 0.7214, Val Loss: 0.7767\n",
      "Epoch 14/32: Train Loss: 0.7153, Val Loss: 0.7828\n",
      "Epoch 15/32: Train Loss: 0.7075, Val Loss: 0.7757\n",
      "Epoch 16/32: Train Loss: 0.6993, Val Loss: 0.7645\n",
      "Epoch 17/32: Train Loss: 0.6924, Val Loss: 0.7671\n",
      "Epoch 18/32: Train Loss: 0.6871, Val Loss: 0.7658\n",
      "Epoch 19/32: Train Loss: 0.6805, Val Loss: 0.7628\n",
      "Epoch 20/32: Train Loss: 0.6780, Val Loss: 0.7618\n",
      "Epoch 21/32: Train Loss: 0.6714, Val Loss: 0.7625\n",
      "Epoch 22/32: Train Loss: 0.6681, Val Loss: 0.7575\n",
      "Epoch 23/32: Train Loss: 0.6616, Val Loss: 0.7622\n",
      "Epoch 24/32: Train Loss: 0.6594, Val Loss: 0.7620\n",
      "Epoch 25/32: Train Loss: 0.6550, Val Loss: 0.7546\n",
      "Epoch 26/32: Train Loss: 0.6506, Val Loss: 0.7597\n",
      "Epoch 27/32: Train Loss: 0.6489, Val Loss: 0.7571\n",
      "Epoch 28/32: Train Loss: 0.6454, Val Loss: 0.7572\n",
      "Epoch 29/32: Train Loss: 0.6412, Val Loss: 0.7532\n",
      "Epoch 30/32: Train Loss: 0.6389, Val Loss: 0.7560\n",
      "Epoch 31/32: Train Loss: 0.6356, Val Loss: 0.7555\n",
      "Epoch 32/32: Train Loss: 0.6321, Val Loss: 0.7485\n"
     ]
    }
   ],
   "source": [
    "model_trainer = trainer.Trainer(max_epochs=32, init_random=None, clip_grads_norm=1.0)\n",
    "model_trainer.fit(model, chembl_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "c03ccc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_generate(prefix, num_chars, model, char_to_idx_mapping, idx_to_char_mapping, temperature=0.0, device=None):\n",
    "    \"\"\"\n",
    "    Simple character-by-character generation function.\n",
    "    \"\"\"\n",
    "\n",
    "    def decode_indices_to_string(encoded_indices: list, idx_to_char_mapping: dict[int, str]):\n",
    "        decoded = ''.join([idx_to_char_mapping[int(inx)] for inx in encoded_indices])\n",
    "        return decoded\n",
    "\n",
    "    def encode_string_to_indices(smiles_string: str, char_to_idx_mapping: dict[str, int]):\n",
    "        encoded = [char_to_idx_mapping[c] for c in smiles_string]\n",
    "        return encoded\n",
    "\n",
    "    model.eval()\n",
    "    generated = prefix\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for i in range(num_chars):\n",
    "            # Encode current text\n",
    "            encoded = torch.nn.functional.one_hot(torch.tensor(encode_string_to_indices(generated, char_to_idx_mapping)), num_classes=len(char_to_idx_mapping))\n",
    "            input_tensor = torch.tensor(encoded, device=device, dtype=torch.float32)\n",
    "            \n",
    "            # Get prediction\n",
    "            output = model(input_tensor.unsqueeze(0))  # Add batch dim\n",
    "            \n",
    "            # Get most likely next token\n",
    "            if temperature > 0:\n",
    "                # Apply temperature scaling\n",
    "                output = output / temperature\n",
    "                probabilities = torch.softmax(output, dim=-1)\n",
    "                next_token = torch.multinomial(probabilities[0, -1, :], num_samples=1).item()\n",
    "            else:\n",
    "                # Default to argmax if temperature is 0\n",
    "                next_token = output[0, -1, :].argmax().item()\n",
    "            \n",
    "            # Decode and append\n",
    "            next_char = decode_indices_to_string([next_token], idx_to_char_mapping)\n",
    "            generated += next_char\n",
    "            \n",
    "            # print(f\"Step {i+1}: Added '{next_char}' -> '{generated}'\")\n",
    "            \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74af18b3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_122935/2233264071.py:21: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  input_tensor = torch.tensor(encoded, device=device, dtype=torch.float32)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=O)c1ccccc1\n",
      "CCCCN1C(=O)c2ccccc2S(=O)(=O)C1\n",
      "CCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCCC(=O)OCC\n",
      "CC(C)(C)NC(=O)Nc1cccc(OCc2ccccc2)c1\n",
      "CCOC(=O)C(=O)Nc1cccc(C(=O)NCCc2ccccc2)c1\n",
      "CCCCCCCCCCCCCCCCOCC(O)COC(CO)C(O)COC\n",
      "CC\n"
     ]
    }
   ],
   "source": [
    "# test by making some molecules\n",
    "print(simple_generate(\"C=O\", 200, model, chembl_mini.char_to_idx, chembl_mini.idx_to_char, temperature=0.5, device='cuda').replace(\" \", \"\\n\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60779f36",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "585d357c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37509879",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb91139e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b359bfe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
