{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d9e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "from data import datasets\n",
    "from training import trainer\n",
    "from modules import ind_generator\n",
    "from analysis import similarity\n",
    "\n",
    "import plots, utilities\n",
    "from IPython.display import display, Markdown\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "768bad72",
   "metadata": {},
   "source": [
    "## Lets begin by loading the dataset\n",
    "\n",
    "The CharSMILESChEMBLIndications dataset contains smiles strings associated with their drug indications (i.e. what diseases or conditions they are able to treat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "dataset = datasets.CharSMILESChEMBLIndications(\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a12d8d5b",
   "metadata": {},
   "source": [
    "## What are some of the most common indications in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8134b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_indications = dataset.all_data.drop(columns=[\"canonical_smiles\"]).sum(axis=0).sort_values(ascending=False)\n",
    "most_frequent_indications_names = most_frequent_indications.index.to_list()\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(20, 5))\n",
    "ax.bar(np.arange(len(most_frequent_indications)), most_frequent_indications.to_numpy())\n",
    "ax.set_xticks(np.arange(len(most_frequent_indications)))\n",
    "labels = ax.set_xticklabels([heading.replace(\"mesh_heading_\", \"\") for heading in most_frequent_indications.index], rotation=90)\n",
    "ax.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1490600",
   "metadata": {},
   "source": [
    "## What do the molecules look like for our most common indication?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f5a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_per_indication = 9  # Visualise a 3x3 grid of drug molecules\n",
    "\n",
    "for indications_filter_index in range(10):\n",
    "    # indications_filter_index = 1\n",
    "    indications_filter_name = most_frequent_indications.index[indications_filter_index]\n",
    "    filtered_molecules = dataset.all_data.filter(items=[\"canonical_smiles\", indications_filter_name])\n",
    "    filtered_molecules = filtered_molecules[filtered_molecules[indications_filter_name]].drop(columns=[indications_filter_name])\n",
    "    filtered_molecules = filtered_molecules.rename(columns={\"canonical_smiles\": indications_filter_name})\n",
    "\n",
    "    smiles_to_draw = [smiles for smiles in filtered_molecules[indications_filter_name][:images_per_indication]]\n",
    "\n",
    "    display(Markdown(f\"## Showing {images_per_indication} example chemical structures for {indications_filter_name}\"))\n",
    "    display(\n",
    "        utilities.draw_molecules_as_grid_from_smiles(\n",
    "            canonical_smiles=smiles_to_draw, \n",
    "            names=[str(i + 1) for i in range(images_per_indication)]  # Just number them\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7694b6",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4634e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ind_generator.SmilesIndGeneratorRNNConfig(\n",
    "    vocab_size = len(dataset.vocab),\n",
    "    num_indications = dataset.num_indications,\n",
    "    num_hiddens = 256,\n",
    "    num_layers = 5,\n",
    "    learning_rate = 1e-3,\n",
    "    weight_decay = 1e-5,\n",
    "    output_dropout = 0.4,\n",
    "    rnn_dropout = 0.4,\n",
    "    state_dropout = 0.4\n",
    ")\n",
    "\n",
    "config_mini = ind_generator.SmilesIndGeneratorRNNConfig(\n",
    "    vocab_size = len(dataset.vocab),\n",
    "    num_indications = dataset.num_indications,\n",
    "    num_hiddens = 64,\n",
    "    num_layers = 5,\n",
    "    learning_rate = 1e-3,\n",
    "    weight_decay = 1e-5,\n",
    "    output_dropout = 0.4,\n",
    "    rnn_dropout = 0.4,\n",
    "    state_dropout = 0.4\n",
    ")\n",
    "\n",
    "model = ind_generator.SmilesIndGeneratorRNN(config_mini)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34229f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_model_path = \"../models/Chembl-Ind-SmilesIndGeneratorRNN-CharSMILESChEMBLIndications-2025-07-31-08-01-18.pt\"\n",
    "\n",
    "train_new = True  # Set false to load a pre-trained model\n",
    "save_model = True  # If trainign a new model, do we want to save it?\n",
    "\n",
    "if train_new:\n",
    "    model_trainer = trainer.Trainer(max_epochs=4, init_random=None, clip_grads_norm=10.0)\n",
    "    model_trainer.fit(model, dataset)\n",
    "\n",
    "    if save_model:\n",
    "        utilities.save_model_weights(\"Chembl-Ind-\", model, dataset)\n",
    "else: \n",
    "    model.load_state_dict(\n",
    "        state_dict= torch.load(load_model_path, weights_only=True),\n",
    "    )\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9497031",
   "metadata": {},
   "outputs": [],
   "source": [
    "if train_new:\n",
    "    losses = utilities.extract_training_losses(model_trainer.metadata)\n",
    "    fig, ax = plots.plot_training_validation_loss(\n",
    "        training_losses = losses['avg_train_losses'], \n",
    "        validation_losses = losses['avg_val_losses']\n",
    "    )\n",
    "    ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa1a8a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.vocab.pad.token, dataset.vocab.pad.char)\n",
    "print(dataset.vocab.bos.token, dataset.vocab.bos.char)\n",
    "print(dataset.vocab.eos.token, dataset.vocab.eos.char)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b16482",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_batch = dataset[20]\n",
    "\n",
    "output, _ = model((test_batch[0].unsqueeze(0).to(device=\"cuda\"), test_batch[1].unsqueeze(0).to(device=\"cuda\")))\n",
    "\n",
    "print(output)\n",
    "\n",
    "print(f\"(Seq Len, vocab size): {test_batch[0].shape}, (Indications): {test_batch[1].shape}, (Seq Len): {test_batch[2].shape}\")\n",
    "print(f\"Input SMILES: {dataset.vocab.decode_tokens(test_batch[2].cpu().numpy())}\")\n",
    "\n",
    "print(f\"Prediction: {dataset.vocab.decode_tokens(output.argmax(dim=-1).squeeze().cpu().numpy())}\")\n",
    "print(f\"Prediction Encoded: {output.argmax(dim=-1).squeeze().cpu().numpy()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4a6230",
   "metadata": {},
   "source": [
    "# Lets generate some  Medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b6f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 3, 3\n",
    "\n",
    "n_chars = 100\n",
    "\n",
    "n_valid = 0\n",
    "n_invalid = 0\n",
    "images = []\n",
    "outputs = []\n",
    "\n",
    "# Get the indices for the (rows * cols) most common drug indications\n",
    "mesh_indices = [dataset.indications_names.index(indication_name) for indication_name in most_frequent_indications_names[:rows * cols]]\n",
    "\n",
    "# We don't always get valid output, so we use a robust generation procedure to allow us to make a few\n",
    "# Attempts at getting a valid output\n",
    "max_attempts = 10\n",
    "for idx in mesh_indices:\n",
    "\n",
    "    output = utilities.robust_generate(\n",
    "        utilities.simple_generate,\n",
    "        max_attempts=max_attempts,\n",
    "        prefix=\"C\",\n",
    "        model=model,\n",
    "        vocab=dataset.vocab,\n",
    "        init_state_tensor = dataset.get_indications_tensor(dataset.indications_names[idx]).unsqueeze(0).to(\"cuda\"),\n",
    "        max_generate=500,\n",
    "        temperature=0.7,\n",
    "        device=\"cuda\"\n",
    "    )\n",
    "\n",
    "    # Throw a warning if this exact output is in the training set\n",
    "    if output in dataset.all_data[\"canonical_smiles\"].tolist():\n",
    "        print(\"\\n WARNING: Exact output found in training, overfitting? \\n\")\n",
    "\n",
    "    if output:\n",
    "        outputs.append(output)\n",
    "        n_valid += 1\n",
    "    if not output:\n",
    "        n_invalid += 1\n",
    "        print(\"Generated SMILES is not valid.\")\n",
    "        outputs.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973cb154",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"## Showing {images_per_indication} example chemical structures for {indications_filter_name}\"))\n",
    "display(\n",
    "    utilities.draw_molecules_as_grid_from_smiles(\n",
    "        canonical_smiles=outputs, \n",
    "        names=[dataset.indications_names[mesh_indices[i]].replace(\"mesh_heading_\", \"\") for i in range(len(outputs))]  # Just number them\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf8ea1b",
   "metadata": {},
   "source": [
    "## Sanity check... \"mesh heading other\" should generate essentially random molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 3, 3\n",
    "\n",
    "n_chars = 100\n",
    "\n",
    "n_valid = 0\n",
    "n_invalid = 0\n",
    "images = []\n",
    "outputs = []\n",
    "\n",
    "# Get the indices for the (rows * cols) \"other\" category\n",
    "mesh_indices = [dataset.indications_names.index(most_frequent_indications_names[4])] * 9\n",
    "\n",
    "# We don't always get valid output, so we use a robust generation procedure to allow us to make a few\n",
    "# Attempts at getting a valid output\n",
    "max_attempts = 5\n",
    "for idx in mesh_indices:\n",
    "\n",
    "    output = utilities.robust_generate(\n",
    "        utilities.simple_generate,\n",
    "        max_attempts=max_attempts,\n",
    "        prefix=\"\",\n",
    "        indications_tensor = dataset.get_indications_tensor(dataset.indications_names[idx]).to(model_trainer.device),\n",
    "        num_chars=500,\n",
    "        model=model,\n",
    "        char_to_idx_mapping=dataset.vocab.char_to_token,\n",
    "        idx_to_char_mapping=dataset.vocab.token_to_char,\n",
    "        temperature=0.7,\n",
    "        device=model_trainer.device\n",
    "    )\n",
    "\n",
    "    # Throw a warning if this exact output is in the training set\n",
    "    if output in dataset.all_data[\"canonical_smiles\"].tolist():\n",
    "        print(\"\\n WARNING: Exact output found in training, overfitting? \\n\")\n",
    "\n",
    "    if output:\n",
    "        outputs.append(output)\n",
    "        n_valid += 1\n",
    "    if not output:\n",
    "        n_invalid += 1\n",
    "        print(\"Generated SMILES is not valid.\")\n",
    "        outputs.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f91c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    utilities.draw_molecules_as_grid_from_smiles(\n",
    "        canonical_smiles=outputs, \n",
    "        names=[dataset.indications_names[mesh_indices[i]].replace(\"mesh_heading_\", \"\") for i in range(len(outputs))]  # Just number them\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38566278",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 3, 3\n",
    "\n",
    "n_chars = 100\n",
    "\n",
    "n_valid = 0\n",
    "n_invalid = 0\n",
    "images = []\n",
    "outputs = []\n",
    "\n",
    "# Get the indices for the (rows * cols) \"other\" category\n",
    "mesh_indices = [dataset.indications_names.index(most_frequent_indications_names[8])] * 9\n",
    "\n",
    "# We don't always get valid output, so we use a robust generation procedure to allow us to make a few\n",
    "# Attempts at getting a valid output\n",
    "max_attempts = 5\n",
    "for idx in mesh_indices:\n",
    "\n",
    "    output = utilities.robust_generate(\n",
    "        utilities.simple_generate,\n",
    "        max_attempts=max_attempts,\n",
    "        prefix=\"\",\n",
    "        indications_tensor = dataset.get_indications_tensor(dataset.indications_names[idx]).to(model_trainer.device),\n",
    "        num_chars=500,\n",
    "        model=model,\n",
    "        char_to_idx_mapping=dataset.vocab.char_to_token,\n",
    "        idx_to_char_mapping=dataset.vocab.token_to_char,\n",
    "        temperature=0.7,\n",
    "        device=model_trainer.device\n",
    "    )\n",
    "\n",
    "    # Throw a warning if this exact output is in the training set\n",
    "    if output in dataset.all_data[\"canonical_smiles\"].tolist():\n",
    "        print(\"\\n WARNING: Exact output found in training, overfitting? \\n\")\n",
    "\n",
    "    if output:\n",
    "        outputs.append(output)\n",
    "        n_valid += 1\n",
    "    if not output:\n",
    "        n_invalid += 1\n",
    "        print(\"Generated SMILES is not valid.\")\n",
    "        outputs.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "044da097",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(\n",
    "    utilities.draw_molecules_as_grid_from_smiles(\n",
    "        canonical_smiles=outputs, \n",
    "        names=[dataset.indications_names[mesh_indices[i]].replace(\"mesh_heading_\", \"\") for i in range(len(outputs))]  # Just number them\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70bce0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Fun outputs:\n",
    "\n",
    "# Insane triple macrocycle\n",
    "#  'N[C@H](CC(C)C)C(=O)N[C@H]1C(=O)N[C@@H](CC(N)=O)C(=O)N[C@H]2C(=O)N[C@H]3C(=O)N[C@H](C(=O)N[C@H](C(=O)O)c4cc(O)cc(O)c4-c4cc3ccc4O)[C@H](O)c3ccc(c(Cl)c3)Oc3cc2cc(c3O[C@@H]2O[C@H](CO)[C@@H](O)[C@H](O)[C@H]2O[C@H]2C[C@](C)(N)[C@H](O)[C@H](C)O2)Oc2ccc(cc2Cl)[C@H]1O',\n",
    "\n",
    "# Amino acid macrocycle, containing cysteine disulfide bridge\n",
    "# 'C(C)[C@@H]1NC(=O)[C@H](CCCCN)NC(=O)[C@@H](Cc2c[nH]c3ccccc23)NC(=O)[C@H](Cc2ccccc2)NC(=O)[C@@H](NC(=O)[C@H](N)Cc2ccccc2)CSSC[C@@H](C(=O)N[C@H](CO)[C@@H](C)O)NC1=O',\n",
    "\n",
    "# Prompt to Generate variants of macrocycles: \n",
    "#  C[C@H]1OC(=O)[C@H](C)[C@@H](O\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d28fd1cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19873af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Â mol = Chem.MolFromSmiles('N[C@H](CC(C)C)C(=O)N[C@H]1C(=O)N[C@@H](CC(N)=O)C(=O)N[C@H]2C(=O)N[C@H]3C(=O)N[C@H](C(=O)N[C@H](C(=O)O)c4cc(O)cc(O)c4-c4cc3ccc4O)[C@H](O)c3ccc(c(Cl)c3)Oc3cc2cc(c3O[C@@H]2O[C@H](CO)[C@@H](O)[C@H](O)[C@H]2O[C@H]2C[C@](C)(N)[C@H](O)[C@H](C)O2)Oc2ccc(cc2Cl)[C@H]1O')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "529755ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "view = utilities.visualise_3d_molecule_from_smiles(outputs[3])\n",
    "view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26cf62f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726add1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plots.plot_umap(\n",
    "    embedding_smiles = dataset.all_data[\"canonical_smiles\"].tolist()[::10],\n",
    "    # query_smiles = outputs,\n",
    "    n_neighbors=7,\n",
    "    min_dist=0.9,\n",
    "    colour_categories = dataset.all_data.drop(columns=[\"canonical_smiles\"]).idxmax(axis=1).tolist()[::10],\n",
    "    tanimoto=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b0e6ea9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5624da10",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e4ff15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "440033de",
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity.compute_similarity_matrix_2(outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c92720a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
