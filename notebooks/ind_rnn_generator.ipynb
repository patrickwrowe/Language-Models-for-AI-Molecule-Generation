{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d9e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "from data import datasets\n",
    "from training import trainer\n",
    "from modules import ind_generator\n",
    "\n",
    "import datetime\n",
    "import plots, utilities\n",
    "from IPython.display import Image, display, Markdown\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.CharSMILESChEMBLIndications(\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54dfbd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a12d8d5b",
   "metadata": {},
   "source": [
    "## What are some of the most common indications in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8134b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "most_frequent_indications = dataset.all_data.drop(columns=[\"canonical_smiles\"]).sum(axis=0).sort_values(ascending=False)\n",
    "most_frequent_indications_names = most_frequent_indications.index.to_list()\n",
    "fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(20, 5))\n",
    "ax.bar(np.arange(len(most_frequent_indications)), most_frequent_indications.to_numpy())\n",
    "ax.set_xticks(np.arange(len(most_frequent_indications)))\n",
    "labels = ax.set_xticklabels([heading.replace(\"mesh_heading_\", \"\") for heading in most_frequent_indications.index], rotation=90)\n",
    "ax.set_yscale(\"log\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1490600",
   "metadata": {},
   "source": [
    "## What do the molecules look like for our most common indication?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c07f5a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for indications_filter_index in range(10):\n",
    "    # indications_filter_index = 1\n",
    "    indications_filter_name = freqs.index[indications_filter_index]\n",
    "    filtered_molecules = dataset.all_data.filter(items=[\"canonical_smiles\", indications_filter_name])\n",
    "    filtered_molecules = filtered_molecules[filtered_molecules[indications_filter_name]].drop(columns=[indications_filter_name])\n",
    "    filtered_molecules = filtered_molecules.rename(columns={\"canonical_smiles\": indications_filter_name})\n",
    "\n",
    "    rows, cols = 3, 3\n",
    "\n",
    "    mols = []\n",
    "    names = []\n",
    "    for i, smiles in enumerate(filtered_molecules[indications_filter_name][:rows * cols]):\n",
    "        mols.append(Chem.MolFromSmiles(smiles))\n",
    "        names.append(str(i + 1))\n",
    "\n",
    "    mols = [[mols[i + j] for i in range(rows)] for j in range(0, cols * rows, rows)]\n",
    "    names = [[names[i + j] for i in range(rows)] for j in range(0, cols * rows, rows)]\n",
    "\n",
    "    display(Markdown(f\"## {rows * cols} most common chemical structures for {indications_filter_name}\"))\n",
    "    display(Draw.MolsMatrixToGridImage(mols, legendsMatrix=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7694b6",
   "metadata": {},
   "source": [
    "# Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4634e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ind_generator.SmilesIndGeneratorRNN(\n",
    "    vocab_size = dataset.vocab_size,\n",
    "    num_indications = dataset.num_indications,\n",
    "    num_hiddens = 256,\n",
    "    num_layers = 5,\n",
    "    learning_rate = 1e-3,\n",
    "    weight_decay = 1e-4,\n",
    "    output_dropout = 0.3,\n",
    "    rnn_dropout = 0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34229f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_model_path = \"../models/Chembl-Ind-SmilesIndGeneratorRNN-CharSMILESChEMBLIndications-2025-07-30-12-27-53.pt\"\n",
    "\n",
    "train_new = False  # Set false to load a pre-trained model\n",
    "save_model = True  # If trainign a new model, do we want to save it?\n",
    "\n",
    "if train_new:\n",
    "    model_trainer = trainer.Trainer(max_epochs=64, init_random=None, clip_grads_norm=10.0)\n",
    "    model_trainer.fit(model, dataset)\n",
    "\n",
    "    if save_model:\n",
    "        utilities.save_model_weights(\"Chembl-Mini-\", model, dataset)\n",
    "else: \n",
    "    model.load_weights(\n",
    "        path = load_model_path,\n",
    "    )\n",
    "    device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9497031",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = utilities.extract_training_losses(model_trainer.metadata)\n",
    "fig, ax = plots.plot_training_validation_loss(\n",
    "    training_losses = losses['avg_train_losses'], \n",
    "    validation_losses = losses['avg_val_losses']\n",
    ")\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b16482",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = dataset[20]\n",
    "\n",
    "output, _ = model(test_batch[0].unsqueeze(0).to(device=model_trainer.device), test_batch[1].unsqueeze(0).to(device=model_trainer.device))\n",
    "\n",
    "print(f\"(Seq Len, vocab size): {test_batch[0].shape}, (Indications): {test_batch[1].shape}, (Seq Len): {test_batch[2].shape}\")\n",
    "print(f\"Input SMILES: {''.join([dataset.idx_to_char[c] for c in test_batch[2].cpu().numpy()])}\")\n",
    "print(f\"Prediction: {''.join([dataset.idx_to_char[c] for c in output.argmax(dim=-1).squeeze().cpu().numpy()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efdb23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find where index == 1\n",
    "print(torch.where(test_batch[1] == 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2e614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.indications_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3bab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_generate(prefix, num_chars, model, indications_tensor, char_to_idx_mapping, idx_to_char_mapping, temperature = 0.0, device=None):\n",
    "    \"\"\"\n",
    "    Simple character-by-character generation function.\n",
    "    \"\"\"\n",
    "\n",
    "    def decode_indices_to_string(encoded_indices: list, idx_to_char_mapping: dict[int, str]):\n",
    "        decoded = ''.join([idx_to_char_mapping[int(inx)] for inx in encoded_indices])\n",
    "        return decoded\n",
    "\n",
    "    def encode_string_to_indices(smiles_string: str, char_to_idx_mapping: dict[str, int]):\n",
    "        encoded = [char_to_idx_mapping[c] for c in smiles_string]\n",
    "        return encoded\n",
    "\n",
    "    model.eval()\n",
    "    generated = prefix\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Initialize state with indications\n",
    "        state = model.init_state(indications_tensor.unsqueeze(0).to(device))  # Add batch dim\n",
    "\n",
    "        # First, process the prefix to get the proper state\n",
    "        if len(prefix) > 0:\n",
    "            prefix_encoded = encode_string_to_indices(prefix, char_to_idx_mapping)\n",
    "            prefix_tensor = torch.nn.functional.one_hot(\n",
    "                torch.tensor(prefix_encoded), \n",
    "                num_classes=len(char_to_idx_mapping)\n",
    "            ).float().to(device)\n",
    "            \n",
    "            # Process prefix through model to get proper state\n",
    "            _, state = model(prefix_tensor.unsqueeze(0), state=state)\n",
    "        \n",
    "        # Now generate new characters one by one\n",
    "        for i in range(num_chars - len(prefix)):\n",
    "            # For generation, we need to feed the last character (or a dummy if this is the first step)\n",
    "            if len(generated) > 0:\n",
    "                last_char = generated[-1]\n",
    "                last_char_idx = char_to_idx_mapping[last_char]\n",
    "            else:\n",
    "                # If no prefix, start with some default (this shouldn't happen with your use case)\n",
    "                last_char_idx = 0\n",
    "            \n",
    "            # Create one-hot encoding for single character\n",
    "            char_tensor = torch.nn.functional.one_hot(\n",
    "                torch.tensor([last_char_idx]), \n",
    "                num_classes=len(char_to_idx_mapping)\n",
    "            ).float().to(device)\n",
    "            \n",
    "            # Get prediction for next character\n",
    "            output, state = model(char_tensor.unsqueeze(0), state=state)  # Add batch dim\n",
    "            \n",
    "            # Get most likely next token\n",
    "            if temperature > 0:\n",
    "                # Apply temperature scaling\n",
    "                output = output / temperature\n",
    "                probabilities = torch.softmax(output, dim=-1)\n",
    "                next_token = torch.multinomial(probabilities[0, -1, :], num_samples=1).item()\n",
    "            else:\n",
    "                # Default to argmax if temperature is 0\n",
    "                next_token = output[0, -1, :].argmax().item()\n",
    "            \n",
    "            # Decode and append\n",
    "            next_char = decode_indices_to_string([next_token], idx_to_char_mapping)\n",
    "\n",
    "            if next_char == 'Â£' or next_char == '': # EOS token\n",
    "            # if next_char == ' ' or next_char == '': # EOS token\n",
    "                break\n",
    "\n",
    "            generated += next_char\n",
    "            \n",
    "            # print(f\"Step {i+1}: Added '{next_char}' -> '{generated}'\")\n",
    "            \n",
    "    return generated\n",
    "\n",
    "def robust_generate(generate_function, max_attempts: int, **kwargs):\n",
    "    n_chars = 100\n",
    "\n",
    "    attempts = 0\n",
    "    valid = False\n",
    "    output = None\n",
    "\n",
    "    while attempts < max_attempts and valid == False:\n",
    "        output = generate_function(**kwargs)\n",
    "\n",
    "        valid = utilities.validate_smiles_string(output)\n",
    "\n",
    "        if valid:\n",
    "            return output\n",
    "        else:\n",
    "            attempts += 1\n",
    "        \n",
    "    print(f\"Could not generate valid molecular sample in {max_attempts} attemtps. Aborting.\")\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4a6230",
   "metadata": {},
   "source": [
    "# Lets generate some  Medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b6f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 3, 3\n",
    "\n",
    "n_chars = 100\n",
    "\n",
    "n_valid = 0\n",
    "n_invalid = 0\n",
    "images = []\n",
    "outputs = []\n",
    "\n",
    "# Get the indices for the (rows * cols) most common drug indications\n",
    "mesh_indices = [dataset.indications_names.index(indication_name) for indication_name in most_frequent_indications_names[:rows * cols]]\n",
    "\n",
    "# We don't always get valid output, so we use a robust generation procedure to allow us to make a few\n",
    "# Attempts at getting a valid output\n",
    "max_attempts = 5\n",
    "for idx in mesh_indices:\n",
    "\n",
    "    output = robust_generate(\n",
    "        simple_generate,\n",
    "        max_attempts=max_attempts,\n",
    "        prefix=\"\",\n",
    "        indications_tensor = dataset.get_indications_tensor(dataset.indications_names[idx]).to(model_trainer.device),\n",
    "        num_chars=500,\n",
    "        model=model,\n",
    "        char_to_idx_mapping=dataset.char_to_idx,\n",
    "        idx_to_char_mapping=dataset.idx_to_char,\n",
    "        temperature=0.7,\n",
    "        device=model_trainer.device\n",
    "\n",
    "    )\n",
    "\n",
    "    if output:\n",
    "        outputs.append(output)\n",
    "        n_valid += 1\n",
    "    if not output:\n",
    "        n_invalid += 1\n",
    "        print(\"Generated SMILES is not valid.\")\n",
    "        outputs.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "973cb154",
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = []\n",
    "names = []\n",
    "for i, smiles in enumerate(outputs):\n",
    "    mols.append(Chem.MolFromSmiles(smiles))\n",
    "    names.append(dataset.indications_names[mesh_indices[i]].replace(\"mesh_heading_\", \"\"))\n",
    "\n",
    "mols = [[mols[i + j] for i in range(rows)] for j in range(0, cols * rows, rows)]\n",
    "names = [[names[i + j] for i in range(rows)] for j in range(0, cols * rows, rows)]\n",
    "\n",
    "display(Draw.MolsMatrixToGridImage(mols, legendsMatrix=names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf8ea1b",
   "metadata": {},
   "source": [
    "## Sanity check... \"mesh heading other\" should generate essentially random molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rows, cols = 3, 3\n",
    "\n",
    "n_chars = 100\n",
    "\n",
    "n_valid = 0\n",
    "n_invalid = 0\n",
    "images = []\n",
    "outputs = []\n",
    "\n",
    "# Get the indices for the (rows * cols) \"other\" category\n",
    "mesh_indices = [-1] * rows * cols\n",
    "\n",
    "# We don't always get valid output, so we use a robust generation procedure to allow us to make a few\n",
    "# Attempts at getting a valid output\n",
    "max_attempts = 5\n",
    "for idx in mesh_indices:\n",
    "\n",
    "    output = robust_generate(\n",
    "        simple_generate,\n",
    "        max_attempts=max_attempts,\n",
    "        prefix=\"\",\n",
    "        indications_tensor = dataset.get_indications_tensor(dataset.indications_names[idx]).to(model_trainer.device),\n",
    "        num_chars=500,\n",
    "        model=model,\n",
    "        char_to_idx_mapping=dataset.char_to_idx,\n",
    "        idx_to_char_mapping=dataset.idx_to_char,\n",
    "        temperature=0.7,\n",
    "        device=model_trainer.device\n",
    "\n",
    "    )\n",
    "\n",
    "    if output:\n",
    "        outputs.append(output)\n",
    "        n_valid += 1\n",
    "    if not output:\n",
    "        n_invalid += 1\n",
    "        print(\"Generated SMILES is not valid.\")\n",
    "        outputs.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f91c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "mols = []\n",
    "names = []\n",
    "for i, smiles in enumerate(outputs):\n",
    "    mols.append(Chem.MolFromSmiles(smiles))\n",
    "    names.append(dataset.indications_names[mesh_indices[i]].replace(\"mesh_heading_\", \"\"))\n",
    "\n",
    "mols = [[mols[i + j] for i in range(rows)] for j in range(0, cols * rows, rows)]\n",
    "names = [[names[i + j] for i in range(rows)] for j in range(0, cols * rows, rows)]\n",
    "\n",
    "display(Draw.MolsMatrixToGridImage(mols, legendsMatrix=names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38566278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
