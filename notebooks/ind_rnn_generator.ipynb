{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d9e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "from data import datasets\n",
    "from training import trainer\n",
    "from modules import ind_generator\n",
    "\n",
    "import datetime\n",
    "import plots, utilities\n",
    "from IPython.display import Image, display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.CharSMILESChEMBLIndications(\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3887f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18378c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d31c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4634e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ind_generator.SmilesIndGeneratorRNN(\n",
    "    vocab_size = dataset.vocab_size,\n",
    "    num_indications = dataset.num_indications,\n",
    "    num_hiddens = 256,\n",
    "    num_layers = 5,\n",
    "    learning_rate = 1e-3,\n",
    "    weight_decay = 1e-4,\n",
    "    output_dropout = 0.3,\n",
    "    rnn_dropout = 0.3,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34229f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# train_new = True  # Set false to load a pre-trained model\n",
    "# save_model = True  # If trainign a new model, do we want to save it?\n",
    "\n",
    "# if train_new:\n",
    "#     model_trainer = trainer.Trainer(max_epochs=16, init_random=None, clip_grads_norm=2.0)\n",
    "#     model_trainer.fit(model, dataset)\n",
    "\n",
    "#     if save_model:\n",
    "#         utilities.save_model_weights(\"Chembl-Mini-\", model, dataset)\n",
    "# else: \n",
    "#     model.load_weights(\n",
    "#         path = load_model_path,\n",
    "#     )\n",
    "#     device=\"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "#     model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e70d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = trainer.Trainer(max_epochs=64, init_random=None, clip_grads_norm=10.0)\n",
    "model_trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14a2ff42",
   "metadata": {},
   "outputs": [],
   "source": [
    "utilities.save_model_weights(\"Chembl-Ind-\", model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9497031",
   "metadata": {},
   "outputs": [],
   "source": [
    "losses = utilities.extract_training_losses(model_trainer.metadata)\n",
    "fig, ax = plots.plot_training_validation_loss(\n",
    "    training_losses = losses['avg_train_losses'], \n",
    "    validation_losses = losses['avg_val_losses']\n",
    ")\n",
    "ax.set_yscale('log')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab870e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = dataset[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3e5cca",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch[0].shape, test_batch[1].shape, test_batch[2].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb98fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, _ = model(test_batch[0].unsqueeze(0).to(device=model_trainer.device), test_batch[1].unsqueeze(0).to(device=model_trainer.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b16482",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Input SMILES: {''.join([dataset.idx_to_char[c] for c in test_batch[2].cpu().numpy()])}\")\n",
    "print(f\"Prediction: {''.join([dataset.idx_to_char[c] for c in output.argmax(dim=-1).squeeze().cpu().numpy()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efdb23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find where index == 1\n",
    "print(torch.where(test_batch[1] == 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2e614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.indications_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3bab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_generate(prefix, num_chars, model, indications_tensor, char_to_idx_mapping, idx_to_char_mapping, temperature = 0.0, device=None):\n",
    "    \"\"\"\n",
    "    Simple character-by-character generation function.\n",
    "    \"\"\"\n",
    "\n",
    "    def decode_indices_to_string(encoded_indices: list, idx_to_char_mapping: dict[int, str]):\n",
    "        decoded = ''.join([idx_to_char_mapping[int(inx)] for inx in encoded_indices])\n",
    "        return decoded\n",
    "\n",
    "    def encode_string_to_indices(smiles_string: str, char_to_idx_mapping: dict[str, int]):\n",
    "        encoded = [char_to_idx_mapping[c] for c in smiles_string]\n",
    "        return encoded\n",
    "\n",
    "    model.eval()\n",
    "    generated = prefix\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # Initialize state with indications\n",
    "        state = model.init_state(indications_tensor.unsqueeze(0).to(device))  # Add batch dim\n",
    "\n",
    "        # First, process the prefix to get the proper state\n",
    "        if len(prefix) > 0:\n",
    "            prefix_encoded = encode_string_to_indices(prefix, char_to_idx_mapping)\n",
    "            prefix_tensor = torch.nn.functional.one_hot(\n",
    "                torch.tensor(prefix_encoded), \n",
    "                num_classes=len(char_to_idx_mapping)\n",
    "            ).float().to(device)\n",
    "            \n",
    "            # Process prefix through model to get proper state\n",
    "            _, state = model(prefix_tensor.unsqueeze(0), state=state)\n",
    "        \n",
    "        # Now generate new characters one by one\n",
    "        for i in range(num_chars - len(prefix)):\n",
    "            # For generation, we need to feed the last character (or a dummy if this is the first step)\n",
    "            if len(generated) > 0:\n",
    "                last_char = generated[-1]\n",
    "                last_char_idx = char_to_idx_mapping[last_char]\n",
    "            else:\n",
    "                # If no prefix, start with some default (this shouldn't happen with your use case)\n",
    "                last_char_idx = 0\n",
    "            \n",
    "            # Create one-hot encoding for single character\n",
    "            char_tensor = torch.nn.functional.one_hot(\n",
    "                torch.tensor([last_char_idx]), \n",
    "                num_classes=len(char_to_idx_mapping)\n",
    "            ).float().to(device)\n",
    "            \n",
    "            # Get prediction for next character\n",
    "            output, state = model(char_tensor.unsqueeze(0), state=state)  # Add batch dim\n",
    "            \n",
    "            # Get most likely next token\n",
    "            if temperature > 0:\n",
    "                # Apply temperature scaling\n",
    "                output = output / temperature\n",
    "                probabilities = torch.softmax(output, dim=-1)\n",
    "                next_token = torch.multinomial(probabilities[0, -1, :], num_samples=1).item()\n",
    "            else:\n",
    "                # Default to argmax if temperature is 0\n",
    "                next_token = output[0, -1, :].argmax().item()\n",
    "            \n",
    "            # Decode and append\n",
    "            next_char = decode_indices_to_string([next_token], idx_to_char_mapping)\n",
    "\n",
    "            if next_char == 'Â£' or next_char == '': # EOS token\n",
    "            # if next_char == ' ' or next_char == '': # EOS token\n",
    "                break\n",
    "\n",
    "            generated += next_char\n",
    "            \n",
    "            # print(f\"Step {i+1}: Added '{next_char}' -> '{generated}'\")\n",
    "            \n",
    "    return generated\n",
    "\n",
    "def robust_generate(generate_function, max_attempts: int, **kwargs):\n",
    "    n_chars = 100\n",
    "\n",
    "    attempts = 0\n",
    "    valid = False\n",
    "    output = None\n",
    "\n",
    "    while attempts < max_attempts and valid == False:\n",
    "        output = generate_function(**kwargs)\n",
    "\n",
    "        valid = utilities.validate_smiles_string(output)\n",
    "\n",
    "        if valid:\n",
    "            return output\n",
    "        else:\n",
    "            attempts += 1\n",
    "        \n",
    "    print(f\"Could not generate valid molecular sample in {max_attempts} attemtps. Aborting.\")\n",
    "    return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4f04917",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, name in enumerate(dataset.indications_names[::10]):\n",
    "    print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4a6230",
   "metadata": {},
   "source": [
    "# Lets generate some  Medications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b6f0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_chars = 100\n",
    "\n",
    "n_valid = 0\n",
    "n_invalid = 0\n",
    "images = []\n",
    "outputs = []\n",
    "mesh_indices = [idx for idx, _ in enumerate(dataset.indications_names[::10])] + [-1]\n",
    "max_attempts = 5\n",
    "for i in mesh_indices:\n",
    "\n",
    "    output = robust_generate(\n",
    "        simple_generate,\n",
    "        max_attempts=max_attempts,\n",
    "        prefix=\"\",\n",
    "        indications_tensor = dataset.get_indications_tensor(dataset.indications_names[i]).to(model_trainer.device),\n",
    "        num_chars=500,\n",
    "        model=model,\n",
    "        char_to_idx_mapping=dataset.char_to_idx,\n",
    "        idx_to_char_mapping=dataset.idx_to_char,\n",
    "        temperature=0.7,\n",
    "        device=model_trainer.device\n",
    "\n",
    "    )\n",
    "\n",
    "    if output:\n",
    "        images.append(utilities.draw_molecule(output))\n",
    "        outputs.append(output)\n",
    "        n_valid += 1\n",
    "    if not output:\n",
    "        n_invalid += 1\n",
    "        print(\"Generated SMILES is not valid.\")\n",
    "        images.append(None)\n",
    "        outputs.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc78484",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"# Generated {n_valid} valid molecules and {n_invalid} invalid SMILES strings out of {len(mesh_indices)} requested molecules.\"))\n",
    "display(Markdown(\"## Generated Molecules\"))\n",
    "for i, mesh_idx in enumerate(mesh_indices):\n",
    "    display(Markdown(f\"### Indication - {dataset.indications_names[mesh_idx]}\"))\n",
    "    display(Markdown(f\"**SMILES:** {outputs[i]}\"))\n",
    "\n",
    "    display(images[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acf8ea1b",
   "metadata": {},
   "source": [
    "## Sanity check... \"mesh heading other\" should generate essentially random molecules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "226d393f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "n_chars = 100\n",
    "\n",
    "n_valid = 0\n",
    "n_invalid = 0\n",
    "images = []\n",
    "outputs = []\n",
    "mesh_indices = [-1] * 10\n",
    "max_attempts = 5\n",
    "\n",
    "for i in mesh_indices:\n",
    "\n",
    "    output = robust_generate(\n",
    "        simple_generate,\n",
    "        max_attempts=max_attempts,\n",
    "        prefix=\"\",\n",
    "        indications_tensor = dataset.get_indications_tensor(dataset.indications_names[i]).to(model_trainer.device),\n",
    "        num_chars=500,\n",
    "        model=model,\n",
    "        char_to_idx_mapping=dataset.char_to_idx,\n",
    "        idx_to_char_mapping=dataset.idx_to_char,\n",
    "        temperature=0.7,\n",
    "        device=model_trainer.device\n",
    "\n",
    "    )\n",
    "\n",
    "    if output:\n",
    "        images.append(utilities.draw_molecule(output))\n",
    "        outputs.append(output)\n",
    "        n_valid += 1\n",
    "    if not output:\n",
    "        n_invalid += 1\n",
    "        print(\"Generated SMILES is not valid.\")\n",
    "        images.append(None)\n",
    "        outputs.append(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f91c17",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Markdown(f\"# Generated {n_valid} valid molecules and {n_invalid} invalid SMILES strings out of {len(mesh_indices)} requested molecules.\"))\n",
    "display(Markdown(\"## Generated Molecules\"))\n",
    "for i, mesh_idx in enumerate(mesh_indices):\n",
    "    display(Markdown(f\"### Indication - {dataset.indications_names[mesh_idx]}\"))\n",
    "    display(Markdown(f\"**SMILES:** {outputs[i]}\"))\n",
    "\n",
    "    display(images[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38566278",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
