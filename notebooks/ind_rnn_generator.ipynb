{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d9e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "from tokenizers import Tokenizer\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import collections\n",
    "import torch\n",
    "\n",
    "from data import datasets\n",
    "from training import trainer\n",
    "from modules import ind_generator\n",
    "import attr\n",
    "\n",
    "import plots, utilities\n",
    "\n",
    "from transformers.tokenization_utils_fast import PreTrainedTokenizerFast\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.CharSMILESChEMBLIndications()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4634e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ind_generator.SmilesIndGeneratorRNN(\n",
    "    vocab_size=dataset.vocab_size,\n",
    "    num_indications=dataset.num_indications,\n",
    "    num_hiddens=250,\n",
    "    num_layers=2,\n",
    "    learning_rate = 0.001,\n",
    "    weight_decay = 0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e70d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = trainer.Trainer(max_epochs=4, init_random=None, clip_grads_norm=1.0)\n",
    "model_trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2e614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.indications_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97f5c1aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_sequence(prefix, indications_tensor, num_chars, model, char_to_idx_mapping, idx_to_char_mapping, temperature = 0.0, device=None):\n",
    "    \"\"\"\n",
    "    Simple character-by-character generation function.\n",
    "    \"\"\"\n",
    "\n",
    "    def decode_indices_to_string(encoded_indices: list, idx_to_char_mapping: dict[int, str]):\n",
    "        decoded = ''.join([idx_to_char_mapping[int(inx)] for inx in encoded_indices])\n",
    "        return decoded\n",
    "\n",
    "    def encode_string_to_indices(smiles_string: str, char_to_idx_mapping: dict[str, int]):\n",
    "        encoded = [char_to_idx_mapping[c] for c in smiles_string]\n",
    "        return encoded\n",
    "\n",
    "    model.eval()\n",
    "    generated = prefix\n",
    "    \n",
    "    # Ensure device is correct\n",
    "    state = indications_tensor.unsqueeze(0).to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for i in range(num_chars):\n",
    "            # Encode current text to indices\n",
    "            encoded_indices = encode_string_to_indices(generated, char_to_idx_mapping)\n",
    "            \n",
    "            # Convert to tensor and create one-hot encoding\n",
    "            indices_tensor = torch.tensor(encoded_indices, device=device)\n",
    "            input_tensor = torch.nn.functional.one_hot(indices_tensor, num_classes=len(char_to_idx_mapping)).float()\n",
    "            \n",
    "            # Get prediction\n",
    "            output, state = model(input_tensor.unsqueeze(0), state) \n",
    "            \n",
    "            # Get most likely next token\n",
    "            if temperature > 0:\n",
    "                # Apply temperature scaling\n",
    "                output = output / temperature\n",
    "                probabilities = torch.softmax(output, dim=-1)\n",
    "                next_token = torch.multinomial(probabilities[0, -1, :], num_samples=1).item()\n",
    "            else:\n",
    "                # Default to argmax if temperature is 0\n",
    "                next_token = output[0, -1, :].argmax().item()\n",
    "            \n",
    "            # Decode and append\n",
    "            next_char = idx_to_char_mapping[next_token]\n",
    "\n",
    "            if next_token == dataset.padding_index or next_char == \"\":\n",
    "                break\n",
    "\n",
    "            \n",
    "            generated += next_char\n",
    "            \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a6230",
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_sequence(\n",
    "    prefix=\"C\",\n",
    "    indications_tensor = dataset.get_indications_tensor(dataset.indications_names[0]),\n",
    "    num_chars=100,\n",
    "    model=model,\n",
    "    char_to_idx_mapping=dataset.char_to_idx,\n",
    "    idx_to_char_mapping=dataset.idx_to_char,\n",
    "    temperature=0.0,\n",
    "    device=model_trainer.device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b6f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
