{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb72c710",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "167d9e13",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "sys.path.append(\"../\")\n",
    "\n",
    "import sys\n",
    "import torch\n",
    "from data import datasets\n",
    "from training import trainer\n",
    "from modules import ind_generator\n",
    "\n",
    "import plots, utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f4a0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = datasets.CharSMILESChEMBLIndications()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3887f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.all_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18378c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d31c853",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[0][1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4634e75a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ind_generator.SmilesIndGeneratorRNN(\n",
    "    vocab_size=dataset.vocab_size,\n",
    "    num_indications=dataset.num_indications,\n",
    "    num_hiddens=256,\n",
    "    num_layers=2,\n",
    "    learning_rate = 1e-4,\n",
    "    weight_decay = 1e-3,\n",
    "    output_dropout=0.2,\n",
    "    rnn_dropout=0.2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e70d50",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_trainer = trainer.Trainer(max_epochs=16, init_random=None, clip_grads_norm=1.0)\n",
    "model_trainer.fit(model, dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab870e29",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_batch = dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb98fc3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output, _ = model(test_batch[0].unsqueeze(0).to(device=model_trainer.device), test_batch[1].unsqueeze(0).to(device=model_trainer.device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62b16482",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Input SMILES: {''.join([dataset.idx_to_char[c] for c in test_batch[2].cpu().numpy()])}\")\n",
    "print(f\"Prediction: {''.join([dataset.idx_to_char[c] for c in output.argmax(dim=-1).squeeze().cpu().numpy()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3efdb23e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find where index == 1\n",
    "print(torch.where(test_batch[1] == 1)[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af2e614b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.indications_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3bab3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_generate(prefix, num_chars, model, indications_tensor, char_to_idx_mapping, idx_to_char_mapping, temperature = 0.0, device=None):\n",
    "    \"\"\"\n",
    "    Simple character-by-character generation function.\n",
    "    \"\"\"\n",
    "\n",
    "    def decode_indices_to_string(encoded_indices: list, idx_to_char_mapping: dict[int, str]):\n",
    "        decoded = ''.join([idx_to_char_mapping[int(inx)] for inx in encoded_indices])\n",
    "        return decoded\n",
    "\n",
    "    def encode_string_to_indices(smiles_string: str, char_to_idx_mapping: dict[str, int]):\n",
    "        encoded = [char_to_idx_mapping[c] for c in smiles_string]\n",
    "        return encoded\n",
    "\n",
    "    model.eval()\n",
    "    generated = prefix\n",
    "\n",
    "    # Initialize state with indications\n",
    "    state = model.init_state(indications_tensor.unsqueeze(0).to(device))  # Add batch dim\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        # First, process the prefix to get the proper state\n",
    "        if len(prefix) > 0:\n",
    "            prefix_encoded = encode_string_to_indices(prefix, char_to_idx_mapping)\n",
    "            prefix_tensor = torch.nn.functional.one_hot(\n",
    "                torch.tensor(prefix_encoded), \n",
    "                num_classes=len(char_to_idx_mapping)\n",
    "            ).float().to(device)\n",
    "            \n",
    "            # Process prefix through model to get proper state\n",
    "            _, state = model(prefix_tensor.unsqueeze(0), state=state)\n",
    "        \n",
    "        # Now generate new characters one by one\n",
    "        for i in range(num_chars):\n",
    "            # For generation, we need to feed the last character (or a dummy if this is the first step)\n",
    "            if len(generated) > 0:\n",
    "                last_char = generated[-1]\n",
    "                last_char_idx = char_to_idx_mapping[last_char]\n",
    "            else:\n",
    "                # If no prefix, start with some default (this shouldn't happen with your use case)\n",
    "                last_char_idx = 0\n",
    "            \n",
    "            # Create one-hot encoding for single character\n",
    "            char_tensor = torch.nn.functional.one_hot(\n",
    "                torch.tensor([last_char_idx]), \n",
    "                num_classes=len(char_to_idx_mapping)\n",
    "            ).float().to(device)\n",
    "            \n",
    "            # Get prediction for next character\n",
    "            output, state = model(char_tensor.unsqueeze(0), state=state)  # Add batch dim\n",
    "            \n",
    "            # Get most likely next token\n",
    "            if temperature > 0:\n",
    "                # Apply temperature scaling\n",
    "                output = output / temperature\n",
    "                probabilities = torch.softmax(output, dim=-1)\n",
    "                next_token = torch.multinomial(probabilities[0, -1, :], num_samples=1).item()\n",
    "            else:\n",
    "                # Default to argmax if temperature is 0\n",
    "                next_token = output[0, -1, :].argmax().item()\n",
    "            \n",
    "            # Decode and append\n",
    "            next_char = decode_indices_to_string([next_token], idx_to_char_mapping)\n",
    "\n",
    "            if next_char == ' ' or next_char == '': # EOS token\n",
    "                break\n",
    "\n",
    "            generated += next_char\n",
    "            \n",
    "            # print(f\"Step {i+1}: Added '{next_char}' -> '{generated}'\")\n",
    "            \n",
    "    return generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4a6230",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_generate(\n",
    "    prefix=\"C1cccc2c(c1)\",\n",
    "    indications_tensor = dataset.get_indications_tensor(dataset.indications_names[4]).to(model_trainer.device),\n",
    "    num_chars=50,\n",
    "    model=model,\n",
    "    char_to_idx_mapping=dataset.char_to_idx,\n",
    "    idx_to_char_mapping=dataset.idx_to_char,\n",
    "    temperature=0.0,\n",
    "    device=model_trainer.device\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d51b6f0a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc78484",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "d2l",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
